{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Trainng first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets\n",
    "\n",
    "from ImageDataset import ImageDataset\n",
    "from TextDataset import TokenizerDataset\n",
    "\n",
    "# flicke image\n",
    "img_ds = ImageDataset(center_crop=True, center_crop_shape=(224, 224), return_label=True) # return label = True\n",
    "img_ds.load('flicker_data/flicker_toy_data/flicker/images/')\n",
    "# text\n",
    "txt_ds = TokenizerDataset(return_label=False) \n",
    "txt_ds.load('flicker_data/flicker_toy_data/text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "(tensor([[[0.5059, 0.5176, 0.5137,  ..., 0.4941, 0.5020, 0.5059],\n",
      "         [0.4980, 0.5020, 0.4980,  ..., 0.4824, 0.5020, 0.5059],\n",
      "         [0.5059, 0.4863, 0.4902,  ..., 0.4980, 0.4980, 0.5137],\n",
      "         ...,\n",
      "         [0.7843, 0.7922, 0.7529,  ..., 0.1412, 0.2078, 0.2196],\n",
      "         [0.9922, 0.9922, 0.9647,  ..., 0.1176, 0.0941, 0.1333],\n",
      "         [0.9961, 0.9922, 1.0000,  ..., 0.1647, 0.1294, 0.1373]],\n",
      "\n",
      "        [[0.5765, 0.5882, 0.5843,  ..., 0.5490, 0.5569, 0.5608],\n",
      "         [0.5686, 0.5804, 0.5765,  ..., 0.5490, 0.5529, 0.5529],\n",
      "         [0.5608, 0.5569, 0.5647,  ..., 0.5569, 0.5490, 0.5529],\n",
      "         ...,\n",
      "         [0.7961, 0.8039, 0.7490,  ..., 0.1373, 0.1882, 0.2000],\n",
      "         [0.9961, 0.9961, 0.9608,  ..., 0.1137, 0.1137, 0.1529],\n",
      "         [0.9922, 0.9922, 1.0000,  ..., 0.1608, 0.1059, 0.1216]],\n",
      "\n",
      "        [[0.6235, 0.6353, 0.6314,  ..., 0.5922, 0.6000, 0.6118],\n",
      "         [0.6078, 0.6235, 0.6196,  ..., 0.5804, 0.5882, 0.6000],\n",
      "         [0.6039, 0.6118, 0.6196,  ..., 0.5843, 0.5843, 0.6000],\n",
      "         ...,\n",
      "         [0.5882, 0.5961, 0.5686,  ..., 0.1216, 0.1765, 0.1882],\n",
      "         [0.7294, 0.7373, 0.7373,  ..., 0.0980, 0.0980, 0.1294],\n",
      "         [0.8745, 0.8431, 0.8627,  ..., 0.1451, 0.1059, 0.1176]]]), tensor(0))\n",
      "[0, 1]\n",
      "['1022454428_b6b660a67b', '103195344_5d2dc613a3', '1055753357_4fa3d8d693', '1124448967_2221af8dc5', '1131804997_177c3c0640', '1138784872_69ade3f2ab', '1142847777_2a0c1c2551', '1143373711_2e90b7b799', '1143882946_1898d2eeb9', '1144288288_e5c9558b6a']\n"
     ]
    }
   ],
   "source": [
    "print(len(img_ds))\n",
    "print(img_ds[0])\n",
    "print(img_ds.get_classes())\n",
    "print(img_ds.get_sample_ids()[0: 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "tensor([  101,  1037,  2158,  1998,  2450,  2729,  2005,  2019, 10527,  2247,\n",
      "         1996,  2217,  1997,  1037,  2303,  1997,  2300,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0])\n",
      "30522\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(txt_ds))\n",
    "print(txt_ds[0]) # word idx\n",
    "print(txt_ds.get_vocab_size()) # vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import server\n",
    "import client_cnn\n",
    "import client_lstm\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch as t\n",
    "\n",
    "import importlib\n",
    "importlib.reload(server)\n",
    "importlib.reload(client_cnn)\n",
    "importlib.reload(client_lstm)\n",
    "\n",
    "cnn = client_cnn.CNNModel()\n",
    "lstm = client_lstm.LSTMModel(vocab_size=txt_ds.get_vocab_size())\n",
    "head = server.ModelHead()\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, cnn, lstm, head):\n",
    "        super(Model, self).__init__()\n",
    "        self.cnn = cnn\n",
    "        self.lstm = lstm\n",
    "        self.head = head\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_cnn, x_lstm):\n",
    "        x_cnn = self.cnn(x_cnn)\n",
    "        x_lstm = self.lstm(x_lstm)\n",
    "        return self.head(self.fc(t.cat([x_cnn, x_lstm], dim=1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([215, 3, 224, 224])\n",
      "torch.Size([215, 26])\n",
      "torch.Size([215])\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "img_batch = [img_ds[i][0] for i in range(len(img_ds))]\n",
    "txt_batch = [txt_ds[i] for i in range(len(txt_ds))]\n",
    "labels = [img_ds[i][1] for i in range(len(img_ds))]\n",
    "\n",
    "\n",
    "img_tens = t.stack(img_batch)\n",
    "txt_tens = t.stack(txt_batch)\n",
    "labels_tens = t.stack(labels).float()\n",
    "print(img_tens.shape)\n",
    "print(txt_tens.shape)\n",
    "print(labels_tens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 1.1720213890075684\n",
      "Epoch 1: Loss 0.7074784636497498\n",
      "Epoch 2: Loss 0.6446720361709595\n",
      "Epoch 3: Loss 0.5930801033973694\n",
      "Epoch 4: Loss 0.5683736205101013\n",
      "Epoch 5: Loss 0.5002675652503967\n",
      "Epoch 6: Loss 0.4807666540145874\n",
      "Epoch 7: Loss 0.42158910632133484\n",
      "Epoch 8: Loss 0.4939461946487427\n",
      "Epoch 9: Loss 0.4604698121547699\n",
      "Epoch 10: Loss 0.3626730144023895\n",
      "Epoch 11: Loss 0.44000664353370667\n",
      "Epoch 12: Loss 0.42830878496170044\n",
      "Epoch 13: Loss 0.38693544268608093\n",
      "Epoch 14: Loss 0.4057055413722992\n",
      "Epoch 15: Loss 0.3823530972003937\n",
      "Epoch 16: Loss 0.46398794651031494\n",
      "Epoch 17: Loss 0.39720460772514343\n",
      "Epoch 18: Loss 0.38344109058380127\n",
      "Epoch 19: Loss 0.5042992234230042\n",
      "Epoch 20: Loss 0.31832048296928406\n",
      "Epoch 21: Loss 0.1801786720752716\n",
      "Epoch 22: Loss 0.14970792829990387\n",
      "Epoch 23: Loss 0.0962759330868721\n",
      "Epoch 24: Loss 0.046406880021095276\n",
      "Epoch 25: Loss 0.04409397393465042\n",
      "Epoch 26: Loss 0.055295076221227646\n",
      "Epoch 27: Loss 0.0652361586689949\n",
      "Epoch 28: Loss 0.018741117790341377\n",
      "Epoch 29: Loss 0.05686592683196068\n",
      "Epoch 30: Loss 0.13159584999084473\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as t\n",
    "epochs = 31 \n",
    "batch_size = 64 \n",
    "\n",
    "model = Model(cnn, lstm, head)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "shuffle =  t.randperm(img_tens.size()[0])\n",
    "\n",
    "train_idx = int(0.8 * img_tens.size()[0])\n",
    "train_img = img_tens[shuffle[:train_idx]]\n",
    "train_txt = txt_tens[shuffle[:train_idx]]\n",
    "train_labels = labels_tens[shuffle[:train_idx]]\n",
    "\n",
    "test_img = img_tens[shuffle[train_idx:]]\n",
    "test_txt = txt_tens[shuffle[train_idx:]]\n",
    "test_labels = labels_tens[shuffle[train_idx:]]\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    perm =  t.randperm(train_img.size()[0])\n",
    "    for i in range(0, train_img.size()[0], batch_size):\n",
    "        idx = perm[i:i+batch_size]\n",
    "        batch_img, batch_txt, batch_labels = train_img[idx], train_txt[idx], train_labels[idx]\n",
    "\n",
    "        pred = model(batch_img, batch_txt)\n",
    "        loss = loss_fn(pred, batch_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {e}: Loss {loss}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9767)\n"
     ]
    }
   ],
   "source": [
    "# check model prediction agains train_labels\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "pred = model(test_img, test_txt)\n",
    "# pred = pred.detach().numpy()\n",
    "# pred = t.Tensor(np.where(pred > 0.5, 1, 0))\n",
    "metrics = BinaryAccuracy()\n",
    "print(metrics(pred.detach(), test_labels.detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma_prep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
