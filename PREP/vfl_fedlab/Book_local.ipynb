{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Trainng first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets\n",
    "\n",
    "from ImageDataset import ImageDataset\n",
    "from TextDataset import TokenizerDataset\n",
    "\n",
    "# flicke image\n",
    "img_ds = ImageDataset(center_crop=True, center_crop_shape=(224, 224), return_label=True) # return label = True\n",
    "img_ds.load('flicker_data/flicker_toy_data/flicker/images/')\n",
    "# text\n",
    "txt_ds = TokenizerDataset(return_label=False) \n",
    "txt_ds.load('flicker_data/flicker_toy_data/text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "(tensor([[[0.5059, 0.5176, 0.5137,  ..., 0.4941, 0.5020, 0.5059],\n",
      "         [0.4980, 0.5020, 0.4980,  ..., 0.4824, 0.5020, 0.5059],\n",
      "         [0.5059, 0.4863, 0.4902,  ..., 0.4980, 0.4980, 0.5137],\n",
      "         ...,\n",
      "         [0.7843, 0.7922, 0.7529,  ..., 0.1412, 0.2078, 0.2196],\n",
      "         [0.9922, 0.9922, 0.9647,  ..., 0.1176, 0.0941, 0.1333],\n",
      "         [0.9961, 0.9922, 1.0000,  ..., 0.1647, 0.1294, 0.1373]],\n",
      "\n",
      "        [[0.5765, 0.5882, 0.5843,  ..., 0.5490, 0.5569, 0.5608],\n",
      "         [0.5686, 0.5804, 0.5765,  ..., 0.5490, 0.5529, 0.5529],\n",
      "         [0.5608, 0.5569, 0.5647,  ..., 0.5569, 0.5490, 0.5529],\n",
      "         ...,\n",
      "         [0.7961, 0.8039, 0.7490,  ..., 0.1373, 0.1882, 0.2000],\n",
      "         [0.9961, 0.9961, 0.9608,  ..., 0.1137, 0.1137, 0.1529],\n",
      "         [0.9922, 0.9922, 1.0000,  ..., 0.1608, 0.1059, 0.1216]],\n",
      "\n",
      "        [[0.6235, 0.6353, 0.6314,  ..., 0.5922, 0.6000, 0.6118],\n",
      "         [0.6078, 0.6235, 0.6196,  ..., 0.5804, 0.5882, 0.6000],\n",
      "         [0.6039, 0.6118, 0.6196,  ..., 0.5843, 0.5843, 0.6000],\n",
      "         ...,\n",
      "         [0.5882, 0.5961, 0.5686,  ..., 0.1216, 0.1765, 0.1882],\n",
      "         [0.7294, 0.7373, 0.7373,  ..., 0.0980, 0.0980, 0.1294],\n",
      "         [0.8745, 0.8431, 0.8627,  ..., 0.1451, 0.1059, 0.1176]]]), tensor(0))\n",
      "[0, 1]\n",
      "['1022454428_b6b660a67b', '103195344_5d2dc613a3', '1055753357_4fa3d8d693', '1124448967_2221af8dc5', '1131804997_177c3c0640', '1138784872_69ade3f2ab', '1142847777_2a0c1c2551', '1143373711_2e90b7b799', '1143882946_1898d2eeb9', '1144288288_e5c9558b6a']\n"
     ]
    }
   ],
   "source": [
    "print(len(img_ds))\n",
    "print(img_ds[0])\n",
    "print(img_ds.get_classes())\n",
    "print(img_ds.get_sample_ids()[0: 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "tensor([  101,  1037,  2158,  1998,  2450,  2729,  2005,  2019, 10527,  2247,\n",
      "         1996,  2217,  1997,  1037,  2303,  1997,  2300,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0])\n",
      "30522\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(txt_ds))\n",
    "print(txt_ds[0]) # word idx\n",
    "print(txt_ds.get_vocab_size()) # vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import server\n",
    "import client_cnn\n",
    "import client_lstm\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch as t\n",
    "\n",
    "import importlib\n",
    "importlib.reload(server)\n",
    "importlib.reload(client_cnn)\n",
    "importlib.reload(client_lstm)\n",
    "\n",
    "cnn = client_cnn.CNNModel()\n",
    "lstm = client_lstm.LSTMModel(vocab_size=txt_ds.get_vocab_size())\n",
    "head = server.ModelHead()\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, cnn, lstm, head):\n",
    "        super(Model, self).__init__()\n",
    "        self.cnn = cnn\n",
    "        self.lstm = lstm\n",
    "        self.head = head\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_cnn, x_lstm):\n",
    "        x_cnn = self.cnn(x_cnn)\n",
    "        x_lstm = self.lstm(x_lstm)\n",
    "        return self.head(self.fc(t.cat([x_cnn, x_lstm], dim=1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([215, 3, 224, 224])\n",
      "torch.Size([215, 26])\n",
      "torch.Size([215])\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "img_batch = [img_ds[i][0] for i in range(len(img_ds))]\n",
    "txt_batch = [txt_ds[i] for i in range(len(txt_ds))]\n",
    "labels = [img_ds[i][1] for i in range(len(img_ds))]\n",
    "\n",
    "\n",
    "img_tens = t.stack(img_batch).to(device='cuda')\n",
    "txt_tens = t.stack(txt_batch).to(device='cuda')\n",
    "labels_tens = t.stack(labels).float().to(device='cuda')\n",
    "print(img_tens.shape)\n",
    "print(txt_tens.shape)\n",
    "print(labels_tens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 193 samples\n",
      "Epoch 0: Loss 0.4850100576877594\n",
      "Epoch 1: Loss 0.5117785930633545\n",
      "Epoch 2: Loss 0.5423750877380371\n",
      "Epoch 3: Loss 0.5007308125495911\n",
      "Epoch 4: Loss 0.4037248492240906\n",
      "Epoch 5: Loss 0.40693843364715576\n",
      "Epoch 6: Loss 0.9687515497207642\n",
      "Epoch 7: Loss 0.8472290635108948\n",
      "Epoch 8: Loss 0.7701170444488525\n",
      "Epoch 9: Loss 0.519010603427887\n",
      "Epoch 10: Loss 0.47176241874694824\n",
      "Epoch 11: Loss 0.30050164461135864\n",
      "Epoch 12: Loss 0.9566352367401123\n",
      "Epoch 13: Loss 0.7088072299957275\n",
      "Epoch 14: Loss 0.6628219485282898\n",
      "Epoch 15: Loss 0.6787374019622803\n",
      "Epoch 16: Loss 0.7092100977897644\n",
      "Epoch 17: Loss 0.7482270002365112\n",
      "Epoch 18: Loss 0.6624841690063477\n",
      "Epoch 19: Loss 0.7508609294891357\n",
      "Epoch 20: Loss 0.6076440215110779\n",
      "Epoch 21: Loss 0.42620471119880676\n",
      "Epoch 22: Loss 0.8953382968902588\n",
      "Epoch 23: Loss 0.5016587972640991\n",
      "Epoch 24: Loss 0.6914321780204773\n",
      "Epoch 25: Loss 0.6378509998321533\n",
      "Epoch 26: Loss 0.27270668745040894\n",
      "Epoch 27: Loss 0.8186789751052856\n",
      "Epoch 28: Loss 0.7518991827964783\n",
      "Epoch 29: Loss 0.9912993907928467\n",
      "Epoch 30: Loss 0.947813868522644\n",
      "Epoch 31: Loss 0.603593647480011\n",
      "Epoch 32: Loss 0.6891983151435852\n",
      "Epoch 33: Loss 0.6717182993888855\n",
      "Epoch 34: Loss 0.8071029186248779\n",
      "Epoch 35: Loss 0.7642762064933777\n",
      "Epoch 36: Loss 0.7057595252990723\n",
      "Epoch 37: Loss 0.727769136428833\n",
      "Epoch 38: Loss 0.6970137357711792\n",
      "Epoch 39: Loss 0.6537104845046997\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as t\n",
    "epochs = 100 \n",
    "batch_size = 64 \n",
    "\n",
    "model = Model(cnn, lstm, head).to('cuda')\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "shuffle =  t.randperm(img_tens.size()[0])\n",
    "\n",
    "train_idx = int(0.9 * img_tens.size()[0])\n",
    "train_img = img_tens[shuffle[:train_idx]]\n",
    "train_txt = txt_tens[shuffle[:train_idx]]\n",
    "train_labels = labels_tens[shuffle[:train_idx]]\n",
    "\n",
    "test_img = img_tens[shuffle[train_idx:]]\n",
    "test_txt = txt_tens[shuffle[train_idx:]]\n",
    "test_labels = labels_tens[shuffle[train_idx:]]\n",
    "\n",
    "print(f\"Training on {train_img.size()[0]} samples\")\n",
    "for e in range(epochs):\n",
    "    \n",
    "    perm =  t.randperm(train_img.size()[0])\n",
    "    for i in range(0, train_img.size()[0], batch_size):\n",
    "        idx = perm[i:i+batch_size]\n",
    "        batch_img, batch_txt, batch_labels = train_img[idx], train_txt[idx], train_labels[idx]\n",
    "\n",
    "        pred = model(batch_img, batch_txt)\n",
    "        loss = loss_fn(pred, batch_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {e}: Loss {loss}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accucary on Test 0.5454545617103577\n"
     ]
    }
   ],
   "source": [
    "# check model prediction agains train_labels\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "pred = model(test_img, test_txt)\n",
    "# pred = pred.detach().numpy()\n",
    "# pred = t.Tensor(np.where(pred > 0.5, 1, 0))\n",
    "metrics = BinaryAccuracy().to('cuda')\n",
    "print(f\"Accucary on Test {metrics(pred.detach(), test_labels.detach())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma_prep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
