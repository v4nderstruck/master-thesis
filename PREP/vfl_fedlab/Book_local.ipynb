{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Trainng first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets\n",
    "\n",
    "from ImageDataset import ImageDataset\n",
    "from TextDataset import TokenizerDataset\n",
    "\n",
    "# flicke image\n",
    "img_ds = ImageDataset(center_crop=True, center_crop_shape=(224, 224), return_label=True) # return label = True\n",
    "img_ds.load('flicker_data/flicker_toy_data/flicker/images/')\n",
    "# text\n",
    "txt_ds = TokenizerDataset(return_label=False) \n",
    "txt_ds.load('flicker_data/flicker_toy_data/text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "(tensor([[[0.5059, 0.5176, 0.5137,  ..., 0.4941, 0.5020, 0.5059],\n",
      "         [0.4980, 0.5020, 0.4980,  ..., 0.4824, 0.5020, 0.5059],\n",
      "         [0.5059, 0.4863, 0.4902,  ..., 0.4980, 0.4980, 0.5137],\n",
      "         ...,\n",
      "         [0.7843, 0.7922, 0.7529,  ..., 0.1412, 0.2078, 0.2196],\n",
      "         [0.9922, 0.9922, 0.9647,  ..., 0.1176, 0.0941, 0.1333],\n",
      "         [0.9961, 0.9922, 1.0000,  ..., 0.1647, 0.1294, 0.1373]],\n",
      "\n",
      "        [[0.5765, 0.5882, 0.5843,  ..., 0.5490, 0.5569, 0.5608],\n",
      "         [0.5686, 0.5804, 0.5765,  ..., 0.5490, 0.5529, 0.5529],\n",
      "         [0.5608, 0.5569, 0.5647,  ..., 0.5569, 0.5490, 0.5529],\n",
      "         ...,\n",
      "         [0.7961, 0.8039, 0.7490,  ..., 0.1373, 0.1882, 0.2000],\n",
      "         [0.9961, 0.9961, 0.9608,  ..., 0.1137, 0.1137, 0.1529],\n",
      "         [0.9922, 0.9922, 1.0000,  ..., 0.1608, 0.1059, 0.1216]],\n",
      "\n",
      "        [[0.6235, 0.6353, 0.6314,  ..., 0.5922, 0.6000, 0.6118],\n",
      "         [0.6078, 0.6235, 0.6196,  ..., 0.5804, 0.5882, 0.6000],\n",
      "         [0.6039, 0.6118, 0.6196,  ..., 0.5843, 0.5843, 0.6000],\n",
      "         ...,\n",
      "         [0.5882, 0.5961, 0.5686,  ..., 0.1216, 0.1765, 0.1882],\n",
      "         [0.7294, 0.7373, 0.7373,  ..., 0.0980, 0.0980, 0.1294],\n",
      "         [0.8745, 0.8431, 0.8627,  ..., 0.1451, 0.1059, 0.1176]]]), tensor(0))\n",
      "[0, 1]\n",
      "['1022454428_b6b660a67b', '103195344_5d2dc613a3', '1055753357_4fa3d8d693', '1124448967_2221af8dc5', '1131804997_177c3c0640', '1138784872_69ade3f2ab', '1142847777_2a0c1c2551', '1143373711_2e90b7b799', '1143882946_1898d2eeb9', '1144288288_e5c9558b6a']\n"
     ]
    }
   ],
   "source": [
    "print(len(img_ds))\n",
    "print(img_ds[0])\n",
    "print(img_ds.get_classes())\n",
    "print(img_ds.get_sample_ids()[0: 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "tensor([  101,  1037,  2158,  1998,  2450,  2729,  2005,  2019, 10527,  2247,\n",
      "         1996,  2217,  1997,  1037,  2303,  1997,  2300,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0])\n",
      "30522\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(txt_ds))\n",
    "print(txt_ds[0]) # word idx\n",
    "print(txt_ds.get_vocab_size()) # vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import server\n",
    "import client_cnn\n",
    "import client_lstm\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch as t\n",
    "\n",
    "import importlib\n",
    "importlib.reload(server)\n",
    "importlib.reload(client_cnn)\n",
    "importlib.reload(client_lstm)\n",
    "\n",
    "cnn = client_cnn.CNNModel()\n",
    "lstm = client_lstm.LSTMModel(vocab_size=txt_ds.get_vocab_size())\n",
    "head = server.ModelHead()\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, cnn, lstm, head):\n",
    "        super(Model, self).__init__()\n",
    "        self.cnn = cnn\n",
    "        self.lstm = lstm\n",
    "        self.head = head\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_cnn, x_lstm):\n",
    "        x_cnn = self.cnn(x_cnn)\n",
    "        x_lstm = self.lstm(x_lstm)\n",
    "        return self.head(self.fc(t.cat([x_cnn, x_lstm], dim=1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([215, 3, 224, 224])\n",
      "torch.Size([215, 26])\n",
      "torch.Size([215])\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "img_batch = [img_ds[i][0] for i in range(len(img_ds))]\n",
    "txt_batch = [txt_ds[i] for i in range(len(txt_ds))]\n",
    "labels = [img_ds[i][1] for i in range(len(img_ds))]\n",
    "\n",
    "\n",
    "img_tens = t.stack(img_batch).to(device='cuda')\n",
    "txt_tens = t.stack(txt_batch).to(device='cuda')\n",
    "labels_tens = t.stack(labels).float().to(device='cuda')\n",
    "print(img_tens.shape)\n",
    "print(txt_tens.shape)\n",
    "print(labels_tens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 193 samples\n",
      "Epoch 0: Loss 0.8068667650222778\n",
      "Epoch 1: Loss 0.7496309280395508\n",
      "Epoch 2: Loss 0.743154764175415\n",
      "Epoch 3: Loss 0.7360532283782959\n",
      "Epoch 4: Loss 0.6602200269699097\n",
      "Epoch 5: Loss 0.7287405133247375\n",
      "Epoch 6: Loss 0.6672695875167847\n",
      "Epoch 7: Loss 0.6663392782211304\n",
      "Epoch 8: Loss 0.7264100909233093\n",
      "Epoch 9: Loss 0.6628686785697937\n",
      "Epoch 10: Loss 0.7344264388084412\n",
      "Epoch 11: Loss 0.7243138551712036\n",
      "Epoch 12: Loss 0.7099851369857788\n",
      "Epoch 13: Loss 0.7106583118438721\n",
      "Epoch 14: Loss 0.6737459897994995\n",
      "Epoch 15: Loss 0.6932549476623535\n",
      "Epoch 16: Loss 0.6781238317489624\n",
      "Epoch 17: Loss 0.6704908013343811\n",
      "Epoch 18: Loss 0.7005823254585266\n",
      "Epoch 19: Loss 0.6808908581733704\n",
      "Epoch 20: Loss 0.6629542708396912\n",
      "Epoch 21: Loss 0.5714950561523438\n",
      "Epoch 22: Loss 0.498330295085907\n",
      "Epoch 23: Loss 0.848120927810669\n",
      "Epoch 24: Loss 0.5352973341941833\n",
      "Epoch 25: Loss 0.4718404710292816\n",
      "Epoch 26: Loss 0.5632936358451843\n",
      "Epoch 27: Loss 0.4828541874885559\n",
      "Epoch 28: Loss 1.0157978534698486\n",
      "Epoch 29: Loss 0.49695780873298645\n",
      "Epoch 30: Loss 0.6048124432563782\n",
      "Epoch 31: Loss 0.5334234237670898\n",
      "Epoch 32: Loss 0.5734156966209412\n",
      "Epoch 33: Loss 0.9479008913040161\n",
      "Epoch 34: Loss 0.8497662544250488\n",
      "Epoch 35: Loss 0.7399148344993591\n",
      "Epoch 36: Loss 0.6708800792694092\n",
      "Epoch 37: Loss 0.7390362024307251\n",
      "Epoch 38: Loss 0.7258839011192322\n",
      "Epoch 39: Loss 0.64654141664505\n",
      "Epoch 40: Loss 0.7452265024185181\n",
      "Epoch 41: Loss 0.7220022678375244\n",
      "Epoch 42: Loss 0.6633209586143494\n",
      "Epoch 43: Loss 0.6788158416748047\n",
      "Epoch 44: Loss 0.7984499335289001\n",
      "Epoch 45: Loss 0.7173764109611511\n",
      "Epoch 46: Loss 0.7282609343528748\n",
      "Epoch 47: Loss 0.7504081130027771\n",
      "Epoch 48: Loss 0.5936985015869141\n",
      "Epoch 49: Loss 0.4778750538825989\n",
      "Epoch 50: Loss 0.6113967895507812\n",
      "Epoch 51: Loss 0.377533882856369\n",
      "Epoch 52: Loss 0.28757455945014954\n",
      "Epoch 53: Loss 0.4902040958404541\n",
      "Epoch 54: Loss 0.27253907918930054\n",
      "Epoch 55: Loss 0.9038616418838501\n",
      "Epoch 56: Loss 0.8233507871627808\n",
      "Epoch 57: Loss 0.7300251722335815\n",
      "Epoch 58: Loss 0.7940443754196167\n",
      "Epoch 59: Loss 0.5884835720062256\n",
      "Epoch 60: Loss 0.6938652992248535\n",
      "Epoch 61: Loss 0.49619847536087036\n",
      "Epoch 62: Loss 0.6410636901855469\n",
      "Epoch 63: Loss 0.8401607275009155\n",
      "Epoch 64: Loss 0.5106163620948792\n",
      "Epoch 65: Loss 0.6323654055595398\n",
      "Epoch 66: Loss 0.7430769801139832\n",
      "Epoch 67: Loss 0.5678673982620239\n",
      "Epoch 68: Loss 0.5437521934509277\n",
      "Epoch 69: Loss 0.33481109142303467\n",
      "Epoch 70: Loss 0.17533302307128906\n",
      "Epoch 71: Loss 0.15141288936138153\n",
      "Epoch 72: Loss 1.0317745208740234\n",
      "Epoch 73: Loss 0.6388559937477112\n",
      "Epoch 74: Loss 0.2627711296081543\n",
      "Epoch 75: Loss 0.8208886981010437\n",
      "Epoch 76: Loss 1.3798285722732544\n",
      "Epoch 77: Loss 0.1567777693271637\n",
      "Epoch 78: Loss 0.35859549045562744\n",
      "Epoch 79: Loss 0.32505035400390625\n",
      "Epoch 80: Loss 0.07862821221351624\n",
      "Epoch 81: Loss 0.3085961639881134\n",
      "Epoch 82: Loss 0.028793420642614365\n",
      "Epoch 83: Loss 0.07690753042697906\n",
      "Epoch 84: Loss 0.20542415976524353\n",
      "Epoch 85: Loss 0.06829388439655304\n",
      "Epoch 86: Loss 0.04480525851249695\n",
      "Epoch 87: Loss 0.01466734055429697\n",
      "Epoch 88: Loss 0.011866714805364609\n",
      "Epoch 89: Loss 0.019297415390610695\n",
      "Epoch 90: Loss 0.2520935833454132\n",
      "Epoch 91: Loss 0.04228178411722183\n",
      "Epoch 92: Loss 0.13848359882831573\n",
      "Epoch 93: Loss 0.06820487231016159\n",
      "Epoch 94: Loss 0.005562715698033571\n",
      "Epoch 95: Loss 0.04798426851630211\n",
      "Epoch 96: Loss 0.03830711543560028\n",
      "Epoch 97: Loss 0.02259594388306141\n",
      "Epoch 98: Loss 0.09389887005090714\n",
      "Epoch 99: Loss 0.10618725419044495\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as t\n",
    "epochs = 100 \n",
    "batch_size = 64 \n",
    "\n",
    "model = Model(cnn, lstm, head).to('cuda')\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "shuffle =  t.randperm(img_tens.size()[0])\n",
    "\n",
    "train_idx = int(0.9 * img_tens.size()[0])\n",
    "train_img = img_tens[shuffle[:train_idx]]\n",
    "train_txt = txt_tens[shuffle[:train_idx]]\n",
    "train_labels = labels_tens[shuffle[:train_idx]]\n",
    "\n",
    "test_img = img_tens[shuffle[train_idx:]]\n",
    "test_txt = txt_tens[shuffle[train_idx:]]\n",
    "test_labels = labels_tens[shuffle[train_idx:]]\n",
    "\n",
    "print(f\"Training on {train_img.size()[0]} samples\")\n",
    "for e in range(epochs):\n",
    "    \n",
    "    perm =  t.randperm(train_img.size()[0])\n",
    "    for i in range(0, train_img.size()[0], batch_size):\n",
    "        idx = perm[i:i+batch_size]\n",
    "        batch_img, batch_txt, batch_labels = train_img[idx], train_txt[idx], train_labels[idx]\n",
    "\n",
    "        pred = model(batch_img, batch_txt)\n",
    "        loss = loss_fn(pred, batch_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {e}: Loss {loss}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accucary on Test 0.7272727489471436\n"
     ]
    }
   ],
   "source": [
    "# check model prediction agains train_labels\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "pred = model(test_img, test_txt)\n",
    "# pred = pred.detach().numpy()\n",
    "# pred = t.Tensor(np.where(pred > 0.5, 1, 0))\n",
    "metrics = BinaryAccuracy().to('cuda')\n",
    "print(f\"Accucary on Test {metrics(pred.detach(), test_labels.detach())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma_prep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
